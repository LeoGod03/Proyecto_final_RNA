{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f96208a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84678c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando dataset...\n",
      "Procesando embeddings...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Cargar el dataset\n",
    "print(\"Cargando dataset...\")\n",
    "dataset = pd.read_json(\"../Datasets/dataset_humor_train_embeddings.json\", lines=True)\n",
    "\n",
    "# 2. Extraer y concatenar los embeddings\n",
    "print(\"Procesando embeddings...\")\n",
    "we_ft = np.stack(dataset['we_ft'].values) # (N, 300)\n",
    "we_mx = np.stack(dataset['we_mx'].values) # (N, 300)\n",
    "we_es = np.stack(dataset['we_es'].values) # (N, 300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "322edbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "def create_minibatches(X, Y, batch_size):\n",
    "    # Recibe los documentos en X y las etiquetas en Y\n",
    "    dataset = TensorDataset(X, Y) # Cargar los datos en un dataset de tensores\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    # loader = DataLoader(dataset, batch_size=batch_size)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a6fe6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guardar_resultados(datos, archivo):\n",
    "\n",
    "    df = pd.DataFrame(datos, columns=['klass'])\n",
    "\n",
    "    df['id'] = df.index + 1\n",
    "\n",
    "    df = df[['id', 'klass']]\n",
    "\n",
    "    df.to_csv(archivo, index=False)\n",
    "\n",
    "    print(f\" {datos} guardado exitosamente!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4976abce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensión final de entrada: (10400, 900)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_full = np.concatenate([we_ft, we_mx, we_es], axis=1) \n",
    "\n",
    "Y_full = dataset['klass'].to_numpy()\n",
    "\n",
    "print(f\"Dimensión final de entrada: {X_full.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4b8b0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (8840, 900), Val: (1560, 900)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3. Dividir en Train y Validation\n",
    "# Usamos stratify para mantener la proporción de humor/no humor\n",
    "X_tr, X_val, Y_train, Y_val = train_test_split(\n",
    "    X_full, Y_full, \n",
    "    test_size=0.15, \n",
    "    random_state=42, \n",
    "    stratify=Y_full\n",
    ")\n",
    "\n",
    "print(f\"Train: {X_tr.shape}, Val: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5a15c600",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size, arquitecture):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        input_size_h1 = arquitecture[0]\n",
    "        input_size_h2 = arquitecture[1]\n",
    "        input_size_h3 = arquitecture[2]\n",
    "\n",
    "        # Capa 1: Recibe muchas características\n",
    "        self.fc1 = nn.Linear(input_size, input_size_h1)\n",
    "        self.bn1 = nn.BatchNorm1d(input_size_h1)\n",
    "        self.act1 = nn.ReLU(0.1)\n",
    "        self.drop1 = nn.Dropout(0.7)\n",
    "        \n",
    "        # Capa 2: Compresión\n",
    "        self.fc2 = nn.Linear(input_size_h1, input_size_h2)\n",
    "        self.bn2 = nn.BatchNorm1d(input_size_h2)\n",
    "        self.act2 = nn.LeakyReLU(0.1)\n",
    "        self.drop2 = nn.Dropout(0.4)\n",
    "\n",
    "        # Capa 3: Refinamiento\n",
    "        self.fc3 = nn.Linear(input_size_h2, input_size_h3)\n",
    "        self.bn3 = nn.BatchNorm1d(input_size_h3)\n",
    "        self.act3 = nn.ReLU(0.1)\n",
    "        self.drop3 = nn.Dropout(0.2)\n",
    "\n",
    "        # Salida\n",
    "        self.output = nn.Linear(input_size_h3, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.drop1(self.act1(self.bn1(self.fc1(x))))\n",
    "        x = self.drop2(self.act2(self.bn2(self.fc2(x))))\n",
    "        x = self.drop3(self.act3(self.bn3(self.fc3(x))))\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9c7288c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. PREPARAR DATOS\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- 0. CARGAR EL ARCHIVO DE TEST ---\n",
    "def test(model):\n",
    "    print(\"Cargando dataset de prueba...\")\n",
    "    dataset_test = pd.read_json(\"../Datasets/dataset_humor_test_embeddings.json\", lines=True)\n",
    "\n",
    "    # --- 1. EXTRACCIÓN Y FUSIÓN DE EMBEDDINGS (CRÍTICO) ---\n",
    "\n",
    "    print(\"Procesando vectores...\")\n",
    "    we_ft_test = np.stack(dataset_test['we_ft'].values) # FastText General\n",
    "    we_mx_test = np.stack(dataset_test['we_mx'].values) # FastText México\n",
    "    we_es_test = np.stack(dataset_test['we_es'].values) # FastText España\n",
    "\n",
    "\n",
    "    X_t = np.concatenate([we_ft_test, we_mx_test, we_es_test], axis=1)\n",
    "\n",
    "    print(f\"Dimensiones de Test listas: {X_t.shape}\") \n",
    "\n",
    "\n",
    "    # Convertir a tensor float\n",
    "    X_testing = torch.from_numpy(X_t).to(torch.float32)\n",
    "\n",
    "\n",
    "    device = next(model.parameters()).device \n",
    "    X_testing = X_testing.to(device)\n",
    "\n",
    "    # 2. INFERENCIA\n",
    "    model.eval() \n",
    "\n",
    "    with torch.no_grad(): \n",
    "        # Predicción de logits\n",
    "        y_pred_test_logits = model(X_testing)\n",
    "\n",
    "    # 3. PROCESAR RESULTADOS\n",
    "    # Obtener la clase (0 o 1) usando argmax\n",
    "    y_pred_test_indices = torch.argmax(y_pred_test_logits, dim=1)\n",
    "\n",
    "\n",
    "    y_pred_final = y_pred_test_indices.cpu().numpy()\n",
    "\n",
    "    print(\"Predicciones generadas:\")\n",
    "    print(y_pred_final)\n",
    "\n",
    "\n",
    "    unique, counts = np.unique(y_pred_final, return_counts=True)\n",
    "    print(\"\\nConteo de clases predichas:\")\n",
    "    print(dict(zip(unique, counts)))\n",
    "    return y_pred_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e3e4755",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BATCH_SIZE = 48\n",
    "LEARNING_RATE = 0.1\n",
    "EPOCHS = 512 \n",
    "FACTOR_BALANCE = 1.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "17e2b41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def ejecutar_experimento(arquitecture, batch_size, lr, epochs, factor_balance = 1.75, patience = 20, guardar = True):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Preparar Tensores\n",
    "    X_train_t = torch.from_numpy(X_tr).float()\n",
    "    Y_train_t = torch.from_numpy(Y_train).long()\n",
    "    X_val_t = torch.from_numpy(X_val).float()\n",
    "    Y_val_tensor = torch.from_numpy(Y_val).long().to(device)\n",
    "\n",
    "    # Parámetros de la red\n",
    "    input_size = X_tr.shape[1]\n",
    "    output_size = 2   # 2 clases\n",
    "\n",
    "    # Inicializar Modelo\n",
    "    model = MLP(input_size=input_size, output_size=output_size, arquitecture=arquitecture)\n",
    "    model.to(device)\n",
    "\n",
    "    classes = np.unique(Y_train)\n",
    "    weights_calc = compute_class_weight('balanced', classes=classes, y=Y_train)\n",
    "\n",
    "\n",
    "    weights_calc[1] = weights_calc[1] * factor_balance\n",
    "    weights = torch.tensor(weights_calc).float().to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=4)\n",
    "\n",
    "    # Variables Early Stopping\n",
    "    best_f1 = 0.0\n",
    "    epochs_no_improve = 0\n",
    "    best_model_path = 'mejor_modelo_fusion.pth'\n",
    "\n",
    "    print(\"--- Iniciando Entrenamiento Fusión (900 inputs) ---\")\n",
    "\n",
    "    for epoch in range(epochs + 1):\n",
    "        model.train()\n",
    "        dataloader = create_minibatches(X_train_t, Y_train_t, batch_size=batch_size)\n",
    "        train_loss = 0\n",
    "        \n",
    "        for X_b, y_b in dataloader:\n",
    "            X_b, y_b = X_b.to(device), y_b.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(X_b)\n",
    "            loss = criterion(output, y_b)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        # --- VALIDACIÓN ---\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            X_v = X_val_t.to(device)\n",
    "            logits = model(X_v)\n",
    "            val_loss = criterion(logits, Y_val_tensor).item()\n",
    "            \n",
    "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "            \n",
    "            # Métrica Objetivo\n",
    "            f1_macro = f1_score(Y_val, preds, average='macro')\n",
    "            acc = accuracy_score(Y_val, preds)\n",
    "            \n",
    "            # Métricas por clase para ver si detectamos el humor\n",
    "            f1_humor = f1_score(Y_val, preds, pos_label=1, average='binary')\n",
    "\n",
    "        print(f\"Ep {epoch+1} | Val Loss: {val_loss:.4f} | F1 Macro: {f1_macro:.4f} (Humor F1: {f1_humor:.4f})\")\n",
    "        \n",
    "        # Paso del Scheduler\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Early Stopping basado en MAXIMIZAR F1 MACRO\n",
    "        if f1_macro > best_f1:\n",
    "            best_f1 = f1_macro\n",
    "            epochs_no_improve = 0\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"  ★ ¡Nuevo Récord! Modelo guardado.\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(\"Early Stopping activado.\")\n",
    "                break\n",
    "\n",
    "    # Cargar el mejor y probar\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "    print(f\"\\nEntrenamiento finalizado. Mejor F1 Macro: {best_f1:.4f}\")\n",
    "\n",
    "    #post entrenamiento\n",
    "    X_val_t = torch.from_numpy(X_val).to(torch.float32)\n",
    "\n",
    "\n",
    "    device = next(model.parameters()).device\n",
    "    X_val_t = X_val_t.to(device)\n",
    "\n",
    "    # 2. INFERENCIA\n",
    "    model.eval() \n",
    "\n",
    "    with torch.no_grad(): # Ahorra memoria y cálculo\n",
    "        # Predicción (Logits)\n",
    "        y_pred_logits = model(X_val_t)\n",
    "        \n",
    "        # Obtener la clase con mayor probabilidad (Argmax)\n",
    "        y_pred_class_tensor = torch.argmax(y_pred_logits, dim=1)\n",
    "\n",
    "    # 3. POST-PROCESAMIENTO\n",
    "\n",
    "    y_pred_val_numpy = y_pred_class_tensor.cpu().numpy()\n",
    "\n",
    "    #print(y_pred_val_numpy)\n",
    "\n",
    "    #print(\"--- Matriz de Confusión ---\")\n",
    "    cm = confusion_matrix(Y_val, y_pred_val_numpy)\n",
    "    #print(cm)\n",
    "\n",
    "    print(\"\\n--- Reporte de Clasificación ---\")\n",
    "\n",
    "    print(classification_report(Y_val, y_pred_val_numpy, digits=4, zero_division='warn', target_names=['No Humor', 'Humor']))\n",
    "    y_pred = test(model)\n",
    "    if(guardar):\n",
    "        nombre_archivo = f\"../Resultados_Leo/neuronas{arquitecture[0]}_{arquitecture[1]}_{arquitecture[2]}, {lr}_900_Embeddings_{batch_size}_balance_{factor_balance}.csv\"\n",
    "        guardar_resultados(y_pred, nombre_archivo)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a71e3600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando Entrenamiento Fusión (900 inputs) ---\n",
      "Ep 1 | Val Loss: 0.4307 | F1 Macro: 0.7607 (Humor F1: 0.7230)\n",
      "  ★ ¡Nuevo Récord! Modelo guardado.\n",
      "Ep 2 | Val Loss: 0.4291 | F1 Macro: 0.7660 (Humor F1: 0.7314)\n",
      "  ★ ¡Nuevo Récord! Modelo guardado.\n",
      "Ep 3 | Val Loss: 0.4719 | F1 Macro: 0.7866 (Humor F1: 0.7271)\n",
      "  ★ ¡Nuevo Récord! Modelo guardado.\n",
      "Ep 4 | Val Loss: 0.4089 | F1 Macro: 0.7640 (Humor F1: 0.7360)\n",
      "Ep 5 | Val Loss: 0.4248 | F1 Macro: 0.7568 (Humor F1: 0.7251)\n",
      "Ep 6 | Val Loss: 0.4079 | F1 Macro: 0.7682 (Humor F1: 0.7368)\n",
      "Ep 7 | Val Loss: 0.3996 | F1 Macro: 0.7463 (Humor F1: 0.7250)\n",
      "Ep 8 | Val Loss: 0.4285 | F1 Macro: 0.8006 (Humor F1: 0.7566)\n",
      "  ★ ¡Nuevo Récord! Modelo guardado.\n",
      "Ep 9 | Val Loss: 0.4066 | F1 Macro: 0.7690 (Humor F1: 0.7337)\n",
      "Ep 10 | Val Loss: 0.4074 | F1 Macro: 0.7974 (Humor F1: 0.7517)\n",
      "Ep 11 | Val Loss: 0.4050 | F1 Macro: 0.7948 (Humor F1: 0.7534)\n",
      "Ep 12 | Val Loss: 0.4081 | F1 Macro: 0.7596 (Humor F1: 0.7293)\n",
      "Ep 13 | Val Loss: 0.4234 | F1 Macro: 0.7850 (Humor F1: 0.7453)\n",
      "Ep 14 | Val Loss: 0.4359 | F1 Macro: 0.7938 (Humor F1: 0.7512)\n",
      "Ep 15 | Val Loss: 0.4585 | F1 Macro: 0.7892 (Humor F1: 0.7508)\n",
      "Ep 16 | Val Loss: 0.4475 | F1 Macro: 0.7541 (Humor F1: 0.7271)\n",
      "Ep 17 | Val Loss: 0.4460 | F1 Macro: 0.7698 (Humor F1: 0.7399)\n",
      "Ep 18 | Val Loss: 0.4727 | F1 Macro: 0.7934 (Humor F1: 0.7532)\n",
      "Ep 19 | Val Loss: 0.4800 | F1 Macro: 0.7604 (Humor F1: 0.7283)\n",
      "Ep 20 | Val Loss: 0.4969 | F1 Macro: 0.7576 (Humor F1: 0.7269)\n",
      "Ep 21 | Val Loss: 0.5029 | F1 Macro: 0.7667 (Humor F1: 0.7323)\n",
      "Ep 22 | Val Loss: 0.4787 | F1 Macro: 0.7944 (Humor F1: 0.7550)\n",
      "Ep 23 | Val Loss: 0.5151 | F1 Macro: 0.7898 (Humor F1: 0.7482)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[70]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mejecutar_experimento\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m48\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.016\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m40\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[69]\u001b[39m\u001b[32m, line 56\u001b[39m, in \u001b[36mejecutar_experimento\u001b[39m\u001b[34m(arquitecture, batch_size, lr, epochs, factor_balance, patience, guardar)\u001b[39m\n\u001b[32m     54\u001b[39m output = model(X_b)\n\u001b[32m     55\u001b[39m loss = criterion(output, y_b)\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m optimizer.step()\n\u001b[32m     58\u001b[39m train_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda\\envs\\gpu_env\\Lib\\site-packages\\torch\\_tensor.py:581\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    571\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    572\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    573\u001b[39m         Tensor.backward,\n\u001b[32m    574\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    579\u001b[39m         inputs=inputs,\n\u001b[32m    580\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m581\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    582\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    583\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda\\envs\\gpu_env\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda\\envs\\gpu_env\\Lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    823\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    824\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m825\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    826\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    827\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    829\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "ejecutar_experimento([256, 128, 32], 48, 0.016, 256, patience=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21a2e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 ... 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_val_t = torch.from_numpy(X_val).to(torch.float32)\n",
    "\n",
    "\n",
    "device = next(model.parameters()).device\n",
    "X_val_t = X_val_t.to(device)\n",
    "\n",
    "# 2. INFERENCIA\n",
    "model.eval() \n",
    "\n",
    "with torch.no_grad(): # Ahorra memoria y cálculo\n",
    "    # Predicción (Logits)\n",
    "    y_pred_logits = model(X_val_t)\n",
    "    \n",
    "    # Obtener la clase con mayor probabilidad (Argmax)\n",
    "    y_pred_class_tensor = torch.argmax(y_pred_logits, dim=1)\n",
    "\n",
    "# 3. POST-PROCESAMIENTO\n",
    "\n",
    "y_pred_val_numpy = y_pred_class_tensor.cpu().numpy()\n",
    "\n",
    "print(y_pred_val_numpy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c3bf7aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Matriz de Confusión ---\n",
      "[[849 139]\n",
      " [126 446]]\n",
      "\n",
      "--- Reporte de Clasificación ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Humor     0.8708    0.8593    0.8650       988\n",
      "       Humor     0.7624    0.7797    0.7710       572\n",
      "\n",
      "    accuracy                         0.8301      1560\n",
      "   macro avg     0.8166    0.8195    0.8180      1560\n",
      "weighted avg     0.8310    0.8301    0.8305      1560\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(\"--- Matriz de Confusión ---\")\n",
    "cm = confusion_matrix(Y_val, y_pred_val_numpy)\n",
    "print(cm)\n",
    "\n",
    "print(\"\\n--- Reporte de Clasificación ---\")\n",
    "\n",
    "print(classification_report(Y_val, y_pred_val_numpy, digits=4, zero_division='warn', target_names=['No Humor', 'Humor']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4b14766d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de ejemplos de prueba\n",
      "klass\n",
      "-1    5600\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_json(\"../Datasets/dataset_humor_test.json\", lines=True)\n",
    "#conteo de clases\n",
    "print(\"Total de ejemplos de prueba\")\n",
    "print(dataset.klass.value_counts())\n",
    "# Extracción de los textos en arreglos de numpy\n",
    "X_test = dataset['text'].to_numpy()\n",
    "# Extracción de las etiquetas o clases de entrenamiento\n",
    "Y_test = dataset['klass'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "92828deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guardar_resultados(datos, archivo):\n",
    "\n",
    "    df = pd.DataFrame(datos, columns=['klass'])\n",
    "\n",
    "    df['id'] = df.index + 1\n",
    "\n",
    "    df = df[['id', 'klass']]\n",
    "\n",
    "    df.to_csv(archivo, index=False)\n",
    "\n",
    "    print(f\" {datos} guardado exitosamente!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11564748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [0 1 0 ... 1 0 1] guardado exitosamente!\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
