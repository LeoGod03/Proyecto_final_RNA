{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f96208a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84678c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando dataset...\n",
      "Procesando embeddings...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Cargar el dataset\n",
    "print(\"Cargando dataset...\")\n",
    "dataset = pd.read_json(\"../Datasets/dataset_humor_train_embeddings.json\", lines=True)\n",
    "\n",
    "# 2. Extraer y concatenar los embeddings\n",
    "print(\"Procesando embeddings...\")\n",
    "we_ft = np.stack(dataset['we_ft'].values) # (N, 300)\n",
    "we_mx = np.stack(dataset['we_mx'].values) # (N, 300)\n",
    "we_es = np.stack(dataset['we_es'].values) # (N, 300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "322edbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "def create_minibatches(X, Y, batch_size):\n",
    "    # Recibe los documentos en X y las etiquetas en Y\n",
    "    dataset = TensorDataset(X, Y) # Cargar los datos en un dataset de tensores\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    # loader = DataLoader(dataset, batch_size=batch_size)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a6fe6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guardar_resultados(datos, archivo):\n",
    "\n",
    "    df = pd.DataFrame(datos, columns=['klass'])\n",
    "\n",
    "    df['id'] = df.index + 1\n",
    "\n",
    "    df = df[['id', 'klass']]\n",
    "\n",
    "    df.to_csv(archivo, index=False)\n",
    "\n",
    "    print(f\" {datos} guardado exitosamente! - archivo: {archivo}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4976abce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensión final de entrada: (10400, 900)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_full = np.concatenate([we_ft, we_mx, we_es], axis=1) \n",
    "\n",
    "Y_full = dataset['klass'].to_numpy()\n",
    "\n",
    "print(f\"Dimensión final de entrada: {X_full.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4b8b0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (8840, 900), Val: (1560, 900)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3. Dividir en Train y Validation\n",
    "# Usamos stratify para mantener la proporción de humor/no humor\n",
    "X_tr, X_val, Y_train, Y_val = train_test_split(\n",
    "    X_full, Y_full, \n",
    "    test_size=0.15, \n",
    "    random_state=42, \n",
    "    stratify=Y_full\n",
    ")\n",
    "\n",
    "print(f\"Train: {X_tr.shape}, Val: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a314a1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.ce = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = self.ce(inputs, targets)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5a15c600",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size, arquitecture):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        input_size_h1 = arquitecture[0]\n",
    "        input_size_h2 = arquitecture[1]\n",
    "        input_size_h3 = arquitecture[2]\n",
    "\n",
    "        # Capa 1: Recibe muchas características\n",
    "        self.fc1 = nn.Linear(input_size, input_size_h1)\n",
    "        self.bn1 = nn.BatchNorm1d(input_size_h1)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.drop1 = nn.Dropout(0.2)\n",
    "        \n",
    "        # Capa 2: Compresión\n",
    "        self.fc2 = nn.Linear(input_size_h1, input_size_h2)\n",
    "        self.bn2 = nn.BatchNorm1d(input_size_h2)\n",
    "        self.act2 = nn.GELU()\n",
    "        self.drop2 = nn.Dropout(0.5)\n",
    "\n",
    "        # Capa 3: Refinamiento\n",
    "        self.fc3 = nn.Linear(input_size_h2, input_size_h3)\n",
    "        self.bn3 = nn.BatchNorm1d(input_size_h3)\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.drop3 = nn.Dropout(0.75)\n",
    "\n",
    "        # Salida\n",
    "        self.output = nn.Linear(input_size_h3, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.drop1(self.act1(self.bn1(self.fc1(x))))\n",
    "        x = self.drop2(self.act2(self.bn2(self.fc2(x))))\n",
    "        x = self.drop3(self.act3(self.bn3(self.fc3(x))))\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9c7288c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. PREPARAR DATOS\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- 0. CARGAR EL ARCHIVO DE TEST ---\n",
    "def test(model):\n",
    "    print(\"Cargando dataset de prueba...\")\n",
    "    dataset_test = pd.read_json(\"../Datasets/dataset_humor_test_embeddings.json\", lines=True)\n",
    "\n",
    "    # --- 1. EXTRACCIÓN Y FUSIÓN DE EMBEDDINGS (CRÍTICO) ---\n",
    "\n",
    "    print(\"Procesando vectores...\")\n",
    "    we_ft_test = np.stack(dataset_test['we_ft'].values) # FastText General\n",
    "    we_mx_test = np.stack(dataset_test['we_mx'].values) # FastText México\n",
    "    we_es_test = np.stack(dataset_test['we_es'].values) # FastText España\n",
    "\n",
    "\n",
    "    X_t = np.concatenate([we_ft_test, we_mx_test, we_es_test], axis=1)\n",
    "\n",
    "    print(f\"Dimensiones de Test listas: {X_t.shape}\") \n",
    "\n",
    "\n",
    "    # Convertir a tensor float\n",
    "    X_testing = torch.from_numpy(X_t).to(torch.float32)\n",
    "\n",
    "\n",
    "    device = next(model.parameters()).device \n",
    "    X_testing = X_testing.to(device)\n",
    "\n",
    "    # 2. INFERENCIA\n",
    "    model.eval() \n",
    "\n",
    "    with torch.no_grad(): \n",
    "        # Predicción de logits\n",
    "        y_pred_test_logits = model(X_testing)\n",
    "\n",
    "    # 3. PROCESAR RESULTADOS\n",
    "    # Obtener la clase (0 o 1) usando argmax\n",
    "    y_pred_test_indices = torch.argmax(y_pred_test_logits, dim=1)\n",
    "\n",
    "\n",
    "    y_pred_final = y_pred_test_indices.cpu().numpy()\n",
    "\n",
    "    print(\"Predicciones generadas:\")\n",
    "    print(y_pred_final)\n",
    "\n",
    "\n",
    "    unique, counts = np.unique(y_pred_final, return_counts=True)\n",
    "    print(\"\\nConteo de clases predichas:\")\n",
    "    print(dict(zip(unique, counts)))\n",
    "    return y_pred_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e3e4755",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BATCH_SIZE = 48\n",
    "LEARNING_RATE = 0.1\n",
    "EPOCHS = 512 \n",
    "FACTOR_BALANCE = 1.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "42e727ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def guardar_log(mensaje, archivo=\"bitacora_experimentos.txt\"):\n",
    "    ahora = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    with open(archivo, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"[{ahora}] {mensaje}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e2b41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def ejecutar_experimento(arquitecture, batch_size, lr, epochs, factor_balance = 1.75, patience = 20):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Preparar Tensores\n",
    "    X_train_t = torch.from_numpy(X_tr).float()\n",
    "    Y_train_t = torch.from_numpy(Y_train).long()\n",
    "    X_val_t = torch.from_numpy(X_val).float()\n",
    "    Y_val_tensor = torch.from_numpy(Y_val).long().to(device)\n",
    "\n",
    "    # Parámetros de la red\n",
    "    input_size = X_tr.shape[1]\n",
    "    output_size = 2   # 2 clases\n",
    "\n",
    "    # Inicializar Modelo\n",
    "    model = MLP(input_size=input_size, output_size=output_size, arquitecture=arquitecture)\n",
    "    model.to(device)\n",
    "\n",
    "    classes = np.unique(Y_train)\n",
    "    weights_calc = compute_class_weight('balanced', classes=classes, y=Y_train)\n",
    "\n",
    "\n",
    "    weights_calc[1] = weights_calc[1] * factor_balance\n",
    "    weights = torch.tensor(weights_calc).float().to(device)\n",
    "\n",
    "    #criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "    criterion = FocalLoss(alpha=0.5, gamma=2.0) # Prueba alpha entre 0.25 y 1\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=4)\n",
    "\n",
    "    # Variables Early Stopping\n",
    "    best_f1 = 0.0\n",
    "    epochs_no_improve = 0\n",
    "    best_model_path = 'mejor_modelo_fusion.pth'\n",
    "\n",
    "    #print(\"--- Iniciando Entrenamiento Fusión (900 inputs) ---\")\n",
    "\n",
    "    for epoch in range(epochs + 1):\n",
    "        model.train()\n",
    "        dataloader = create_minibatches(X_train_t, Y_train_t, batch_size=batch_size)\n",
    "        train_loss = 0\n",
    "        \n",
    "        for X_b, y_b in dataloader:\n",
    "            X_b, y_b = X_b.to(device), y_b.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(X_b)\n",
    "            loss = criterion(output, y_b)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        # --- VALIDACIÓN ---\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            X_v = X_val_t.to(device)\n",
    "            logits = model(X_v)\n",
    "            val_loss = criterion(logits, Y_val_tensor).item()\n",
    "            \n",
    "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "            \n",
    "            # Métrica Objetivo\n",
    "            f1_macro = f1_score(Y_val, preds, average='macro')\n",
    "            acc = accuracy_score(Y_val, preds)\n",
    "            \n",
    "            # Métricas por clase para ver si detectamos el humor\n",
    "            f1_humor = f1_score(Y_val, preds, pos_label=1, average='binary')\n",
    "\n",
    "        print(f\"Ep {epoch+1} | Val Loss: {val_loss:.4f} | F1 Macro: {f1_macro:.4f} (Humor F1: {f1_humor:.4f})\")\n",
    "        \n",
    "        # Paso del Scheduler\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Early Stopping basado en MAXIMIZAR F1 MACRO\n",
    "        if f1_macro > best_f1:\n",
    "            best_f1 = f1_macro\n",
    "            epochs_no_improve = 0\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"¡Nuevo Récord! Modelo guardado.\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(\"Early Stopping activado.\")\n",
    "                break\n",
    "\n",
    "    # Cargar el mejor y probar\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "   \n",
    "\n",
    "    #post entrenamiento\n",
    "    X_val_t = torch.from_numpy(X_val).to(torch.float32)\n",
    "\n",
    "\n",
    "    device = next(model.parameters()).device\n",
    "    X_val_t = X_val_t.to(device)\n",
    "\n",
    "    # 2. INFERENCIA\n",
    "    model.eval() \n",
    "\n",
    "    with torch.no_grad(): # Ahorra memoria y cálculo\n",
    "        # Predicción (Logits)\n",
    "        y_pred_logits = model(X_val_t)\n",
    "        \n",
    "        # Obtener la clase con mayor probabilidad (Argmax)\n",
    "        y_pred_class_tensor = torch.argmax(y_pred_logits, dim=1)\n",
    "\n",
    "    # 3. POST-PROCESAMIENTO\n",
    "\n",
    "    y_pred_val_numpy = y_pred_class_tensor.cpu().numpy()\n",
    "\n",
    "    #print(y_pred_val_numpy)\n",
    "\n",
    "    #print(\"--- Matriz de Confusión ---\")\n",
    "    cm = confusion_matrix(Y_val, y_pred_val_numpy)\n",
    "    #print(cm)\n",
    "\n",
    "    print(\"\\n--- Reporte de Clasificación ---\")\n",
    "\n",
    "    print(classification_report(Y_val, y_pred_val_numpy, digits=4, zero_division='warn', target_names=['No Humor', 'Humor']))\n",
    "    y_pred = test(model)\n",
    "    nombre_archivo = f\"../Resultados_Leo/neuronas{arquitecture[0]}_{arquitecture[1]}_{arquitecture[2]}, {lr}_900_Embeddings_{batch_size}_balance_{factor_balance}.csv\"\n",
    "    print(f\"\\nExperimento finalizado. Mejor F1 Macro: {best_f1:.4f}\")\n",
    "    return y_pred , nombre_archivo, best_f1\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5d9112c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 | Val Loss: 0.0285 | F1 Macro: 0.7665 (Humor F1: 0.7188)\n",
      "¡Nuevo Récord! Modelo guardado.\n",
      "Ep 2 | Val Loss: 0.0289 | F1 Macro: 0.7760 (Humor F1: 0.7374)\n",
      "¡Nuevo Récord! Modelo guardado.\n",
      "Ep 3 | Val Loss: 0.0271 | F1 Macro: 0.7939 (Humor F1: 0.7502)\n",
      "¡Nuevo Récord! Modelo guardado.\n",
      "Ep 4 | Val Loss: 0.0269 | F1 Macro: 0.8069 (Humor F1: 0.7649)\n",
      "¡Nuevo Récord! Modelo guardado.\n",
      "Ep 5 | Val Loss: 0.0274 | F1 Macro: 0.7986 (Humor F1: 0.7529)\n",
      "Ep 6 | Val Loss: 0.0277 | F1 Macro: 0.8074 (Humor F1: 0.7598)\n",
      "¡Nuevo Récord! Modelo guardado.\n",
      "Ep 7 | Val Loss: 0.0299 | F1 Macro: 0.7648 (Humor F1: 0.7303)\n",
      "Ep 8 | Val Loss: 0.0313 | F1 Macro: 0.7792 (Humor F1: 0.7447)\n",
      "Ep 9 | Val Loss: 0.0307 | F1 Macro: 0.7836 (Humor F1: 0.7451)\n",
      "Ep 10 | Val Loss: 0.0314 | F1 Macro: 0.7942 (Humor F1: 0.7542)\n",
      "Ep 11 | Val Loss: 0.0320 | F1 Macro: 0.7943 (Humor F1: 0.7546)\n",
      "Ep 12 | Val Loss: 0.0330 | F1 Macro: 0.7880 (Humor F1: 0.7500)\n",
      "Ep 13 | Val Loss: 0.0352 | F1 Macro: 0.7973 (Humor F1: 0.7545)\n",
      "Ep 14 | Val Loss: 0.0356 | F1 Macro: 0.7815 (Humor F1: 0.7444)\n",
      "Ep 15 | Val Loss: 0.0371 | F1 Macro: 0.7948 (Humor F1: 0.7548)\n",
      "Ep 16 | Val Loss: 0.0379 | F1 Macro: 0.7972 (Humor F1: 0.7527)\n",
      "Ep 17 | Val Loss: 0.0415 | F1 Macro: 0.7822 (Humor F1: 0.7454)\n",
      "Ep 18 | Val Loss: 0.0401 | F1 Macro: 0.7906 (Humor F1: 0.7492)\n",
      "Ep 19 | Val Loss: 0.0452 | F1 Macro: 0.7620 (Humor F1: 0.7288)\n",
      "Ep 20 | Val Loss: 0.0414 | F1 Macro: 0.7959 (Humor F1: 0.7556)\n",
      "Ep 21 | Val Loss: 0.0457 | F1 Macro: 0.7730 (Humor F1: 0.7364)\n",
      "Ep 22 | Val Loss: 0.0408 | F1 Macro: 0.7950 (Humor F1: 0.7524)\n",
      "Ep 23 | Val Loss: 0.0423 | F1 Macro: 0.7943 (Humor F1: 0.7532)\n",
      "Ep 24 | Val Loss: 0.0453 | F1 Macro: 0.7917 (Humor F1: 0.7500)\n",
      "Ep 25 | Val Loss: 0.0452 | F1 Macro: 0.7746 (Humor F1: 0.7373)\n",
      "Ep 26 | Val Loss: 0.0460 | F1 Macro: 0.7937 (Humor F1: 0.7494)\n",
      "Ep 27 | Val Loss: 0.0462 | F1 Macro: 0.7906 (Humor F1: 0.7478)\n",
      "Ep 28 | Val Loss: 0.0457 | F1 Macro: 0.7901 (Humor F1: 0.7490)\n",
      "Ep 29 | Val Loss: 0.0503 | F1 Macro: 0.7674 (Humor F1: 0.7333)\n",
      "Ep 30 | Val Loss: 0.0483 | F1 Macro: 0.7928 (Humor F1: 0.7526)\n",
      "Ep 31 | Val Loss: 0.0466 | F1 Macro: 0.7774 (Humor F1: 0.7390)\n",
      "Ep 32 | Val Loss: 0.0512 | F1 Macro: 0.7755 (Humor F1: 0.7409)\n",
      "Ep 33 | Val Loss: 0.0464 | F1 Macro: 0.7978 (Humor F1: 0.7547)\n",
      "Ep 34 | Val Loss: 0.0512 | F1 Macro: 0.7850 (Humor F1: 0.7453)\n",
      "Ep 35 | Val Loss: 0.0514 | F1 Macro: 0.7739 (Humor F1: 0.7382)\n",
      "Ep 36 | Val Loss: 0.0498 | F1 Macro: 0.7821 (Humor F1: 0.7450)\n",
      "Ep 37 | Val Loss: 0.0500 | F1 Macro: 0.7807 (Humor F1: 0.7430)\n",
      "Ep 38 | Val Loss: 0.0483 | F1 Macro: 0.7839 (Humor F1: 0.7445)\n",
      "Ep 39 | Val Loss: 0.0495 | F1 Macro: 0.7758 (Humor F1: 0.7366)\n",
      "Ep 40 | Val Loss: 0.0504 | F1 Macro: 0.7770 (Humor F1: 0.7396)\n",
      "Ep 41 | Val Loss: 0.0519 | F1 Macro: 0.7709 (Humor F1: 0.7358)\n",
      "Ep 42 | Val Loss: 0.0491 | F1 Macro: 0.7839 (Humor F1: 0.7445)\n",
      "Ep 43 | Val Loss: 0.0486 | F1 Macro: 0.7937 (Humor F1: 0.7526)\n",
      "Ep 44 | Val Loss: 0.0506 | F1 Macro: 0.7698 (Humor F1: 0.7332)\n",
      "Ep 45 | Val Loss: 0.0511 | F1 Macro: 0.7792 (Humor F1: 0.7425)\n",
      "Ep 46 | Val Loss: 0.0477 | F1 Macro: 0.7906 (Humor F1: 0.7492)\n",
      "Early Stopping activado.\n",
      "\n",
      "--- Reporte de Clasificación ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Humor     0.8685    0.8421    0.8551       988\n",
      "       Humor     0.7409    0.7797    0.7598       572\n",
      "\n",
      "    accuracy                         0.8192      1560\n",
      "   macro avg     0.8047    0.8109    0.8074      1560\n",
      "weighted avg     0.8217    0.8192    0.8201      1560\n",
      "\n",
      "Cargando dataset de prueba...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leopa\\AppData\\Local\\Temp\\ipykernel_3456\\2076789777.py:94: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando vectores...\n",
      "Dimensiones de Test listas: (5600, 900)\n",
      "Predicciones generadas:\n",
      "[1 0 0 ... 1 0 1]\n",
      "\n",
      "Conteo de clases predichas:\n",
      "{np.int64(0): np.int64(3301), np.int64(1): np.int64(2299)}\n",
      "\n",
      "Experimento finalizado. Mejor F1 Macro: 0.8074\n"
     ]
    }
   ],
   "source": [
    "configuracion = {\n",
    "    \"capas\": [512, 256, 512],\n",
    "    \"batch_size\": 48,\n",
    "    \"learning_rate\": 0.0002,\n",
    "    \"patience\": 40,\n",
    "    \"epochs\": 256,\n",
    "    \"factor_balance\": 0.75\n",
    "}\n",
    "\n",
    "y_pred, nombre_archivo, best_f1 = ejecutar_experimento(configuracion[\"capas\"], configuracion[\"batch_size\"], configuracion[\"learning_rate\"],\n",
    "                                                        configuracion[\"epochs\"], patience=configuracion[\"patience\"], factor_balance=configuracion[\"factor_balance\"])\n",
    "\n",
    "configuracion['f1_score_best'] = best_f1\n",
    "texto_a_guardar = f\"Experimento #{1}: Config={configuracion}\"\n",
    "   \n",
    "    \n",
    "guardar_log(texto_a_guardar, archivo=\"bitacora_experimentos_exp_29_11_V2.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fbcdf6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [0 1 0 ... 1 0 1] guardado exitosamente! - archivo: ../Resultados_Leo/Prob_drop_29_2.csv\n"
     ]
    }
   ],
   "source": [
    "guardar_resultados(y_pred, \"../Resultados_Leo/Prob_drop_29_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a71e3600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 | Val Loss: 0.4505 | F1 Macro: 0.7630 (Humor F1: 0.6761)\n",
      "¡Nuevo Récord! Modelo guardado.\n",
      "Ep 2 | Val Loss: 0.4626 | F1 Macro: 0.7143 (Humor F1: 0.5890)\n",
      "Ep 3 | Val Loss: 0.4349 | F1 Macro: 0.7787 (Humor F1: 0.7166)\n",
      "¡Nuevo Récord! Modelo guardado.\n",
      "Ep 4 | Val Loss: 0.4376 | F1 Macro: 0.7698 (Humor F1: 0.6978)\n",
      "Ep 5 | Val Loss: 0.4419 | F1 Macro: 0.7576 (Humor F1: 0.6660)\n",
      "Ep 6 | Val Loss: 0.4994 | F1 Macro: 0.7687 (Humor F1: 0.7159)\n",
      "Ep 7 | Val Loss: 0.4920 | F1 Macro: 0.7795 (Humor F1: 0.7251)\n",
      "¡Nuevo Récord! Modelo guardado.\n",
      "Ep 8 | Val Loss: 0.5177 | F1 Macro: 0.7615 (Humor F1: 0.7204)\n",
      "Ep 9 | Val Loss: 0.4804 | F1 Macro: 0.7783 (Humor F1: 0.7164)\n",
      "Ep 10 | Val Loss: 0.5013 | F1 Macro: 0.7827 (Humor F1: 0.7214)\n",
      "¡Nuevo Récord! Modelo guardado.\n",
      "Ep 11 | Val Loss: 0.5531 | F1 Macro: 0.7844 (Humor F1: 0.7242)\n",
      "¡Nuevo Récord! Modelo guardado.\n",
      "Ep 12 | Val Loss: 0.5712 | F1 Macro: 0.7764 (Humor F1: 0.7245)\n",
      "Ep 13 | Val Loss: 0.5733 | F1 Macro: 0.7809 (Humor F1: 0.7173)\n",
      "Ep 14 | Val Loss: 0.6218 | F1 Macro: 0.7660 (Humor F1: 0.7126)\n",
      "Ep 15 | Val Loss: 0.6654 | F1 Macro: 0.7612 (Humor F1: 0.6976)\n",
      "Ep 16 | Val Loss: 0.6655 | F1 Macro: 0.7802 (Humor F1: 0.7152)\n",
      "Ep 17 | Val Loss: 0.7129 | F1 Macro: 0.7781 (Humor F1: 0.7094)\n",
      "Ep 18 | Val Loss: 0.6815 | F1 Macro: 0.7742 (Humor F1: 0.7125)\n",
      "Ep 19 | Val Loss: 0.6779 | F1 Macro: 0.7706 (Humor F1: 0.7079)\n",
      "Ep 20 | Val Loss: 0.7405 | F1 Macro: 0.7735 (Humor F1: 0.7142)\n",
      "Ep 21 | Val Loss: 0.7421 | F1 Macro: 0.7615 (Humor F1: 0.7048)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch_size, lr, factor \u001b[38;5;129;01min\u001b[39;00m itertools.product(batch_size_prop, lr_prop, factor_balance):\n\u001b[32m     17\u001b[39m     configuracion = {\n\u001b[32m     18\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcapas\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[32m256\u001b[39m, \u001b[32m128\u001b[39m, \u001b[32m64\u001b[39m],\n\u001b[32m     19\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mbatch_size\u001b[39m\u001b[33m\"\u001b[39m: batch_size,\n\u001b[32m   (...)\u001b[39m\u001b[32m     23\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mfactor_balance\u001b[39m\u001b[33m\"\u001b[39m: factor\n\u001b[32m     24\u001b[39m     }\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     y_pred, nombre_archivo, best_f1 = \u001b[43mejecutar_experimento\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfiguracion\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapas\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfiguracion\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbatch_size\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfiguracion\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlearning_rate\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m                                                        \u001b[49m\u001b[43mconfiguracion\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mepochs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfiguracion\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpatience\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfactor_balance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfiguracion\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfactor_balance\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m     configuracion[\u001b[33m'\u001b[39m\u001b[33mf1_score_best\u001b[39m\u001b[33m'\u001b[39m] = best_f1\n\u001b[32m     30\u001b[39m     texto_a_guardar = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExperimento #\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperimento\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: Config=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfiguracion\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 58\u001b[39m, in \u001b[36mejecutar_experimento\u001b[39m\u001b[34m(arquitecture, batch_size, lr, epochs, factor_balance, patience)\u001b[39m\n\u001b[32m     56\u001b[39m     loss.backward()\n\u001b[32m     57\u001b[39m     optimizer.step()\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     train_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# --- VALIDACIÓN ---\u001b[39;00m\n\u001b[32m     61\u001b[39m model.eval()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "#capa1_prop = [1024]\n",
    "#capa2_prop = [1024,512, 256]\n",
    "#capa3_prop = [1024,512, 256]\n",
    "\n",
    "batch_size_prop = [48, 56, 64]\n",
    "\n",
    "lr_prop = [0.01, 0.025, 0.0025, 0.1, 0.25]\n",
    "\n",
    "factor_balance = [0.5, 0.75, 0.8, 1, 1.25, 1.5, 1.75, 1.85]\n",
    "resultados = []\n",
    "experimento = 1\n",
    "for batch_size, lr, factor in itertools.product(batch_size_prop, lr_prop, factor_balance):\n",
    "\n",
    "    configuracion = {\n",
    "        \"capas\": [256, 128, 64],\n",
    "        \"batch_size\": batch_size,\n",
    "        \"learning_rate\": lr,\n",
    "        \"patience\": 40,\n",
    "        \"epochs\": 256,\n",
    "        \"factor_balance\": factor\n",
    "    }\n",
    "\n",
    "    y_pred, nombre_archivo, best_f1 = ejecutar_experimento(configuracion[\"capas\"], configuracion[\"batch_size\"], configuracion[\"learning_rate\"],\n",
    "                                                        configuracion[\"epochs\"], patience=configuracion[\"patience\"], factor_balance=configuracion[\"factor_balance\"])\n",
    "\n",
    "    configuracion['f1_score_best'] = best_f1\n",
    "    texto_a_guardar = f\"Experimento #{experimento}: Config={configuracion}\"\n",
    "    if experimento % 100 == 0:\n",
    "        df_resultados = pd.DataFrame(resultados)\n",
    "        df_resultados.to_csv(\"resultados_exp_22_11_V2.csv\", index=False)\n",
    "    resultados.append(configuracion)\n",
    "    \n",
    "    guardar_log(texto_a_guardar, archivo=\"bitacora_experimentos_exp_22_11_V2.txt\")\n",
    "    \n",
    "    if best_f1 > 0.82:\n",
    "        nombre_archivo = f'../Resultados_Leo_V3/experimentos_V3_{experimento}.csv'\n",
    "        guardar_resultados(y_pred, nombre_archivo)\n",
    "    \n",
    "    experimento += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1cb09936",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leopa\\AppData\\Local\\Temp\\ipykernel_11464\\3315706254.py:94: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Reporte de Clasificación ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Humor     0.8650    0.8755    0.8702       988\n",
      "       Humor     0.7804    0.7640    0.7721       572\n",
      "\n",
      "    accuracy                         0.8346      1560\n",
      "   macro avg     0.8227    0.8197    0.8212      1560\n",
      "weighted avg     0.8340    0.8346    0.8342      1560\n",
      "\n",
      "Cargando dataset de prueba...\n",
      "Procesando vectores...\n",
      "Dimensiones de Test listas: (5600, 900)\n",
      "Predicciones generadas:\n",
      "[0 1 0 ... 1 0 1]\n",
      "\n",
      "Conteo de clases predichas:\n",
      "{np.int64(0): np.int64(3513), np.int64(1): np.int64(2087)}\n",
      "\n",
      "Experimento finalizado. Mejor F1 Macro: 0.8212\n"
     ]
    }
   ],
   "source": [
    "configuracion = {\n",
    "        \"capas\": [1024, 1024, 1024],\n",
    "        \"batch_size\": 48,\n",
    "        \"learning_rate\": 0.1,\n",
    "        \"patience\": 40,\n",
    "        \"epochs\": 256,\n",
    "        \"factor_balance\": 0.75\n",
    "    }\n",
    "\n",
    "y_pred, _, _ = ejecutar_experimento(configuracion[\"capas\"], configuracion[\"batch_size\"], configuracion[\"learning_rate\"],\n",
    "                                                        configuracion[\"epochs\"], patience=configuracion[\"patience\"], factor_balance=configuracion[\"factor_balance\"])\n",
    "\n",
    "nombre_archivo = '../Resultados_Leo/experimentos_176.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "11564748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [0 1 0 ... 1 0 1] guardado exitosamente!\n"
     ]
    }
   ],
   "source": [
    "guardar_resultados(y_pred,nombre_archivo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
